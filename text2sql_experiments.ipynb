{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58b9dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import contextlib\n",
    "import io\n",
    "import mysql.connector\n",
    "import mysql.connector.errors\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import re\n",
    "import text2sql.cfg as cfg\n",
    "import timeit\n",
    "from text2sql.cfg.parser import text2sqlParser, text2sqlListener, text2sqlLexer\n",
    "from antlr4.InputStream import InputStream\n",
    "from antlr4 import ParseTreeWalker, CommonTokenStream\n",
    "from config import CONFIG\n",
    "from llm.azure_client import AzureClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfff894",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset(path: str) -> dict:\n",
    "    with open(path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        questions = []\n",
    "        queries = []\n",
    "        for line in lines:\n",
    "            if line.startswith('Vraag: '):\n",
    "                questions.append(line.replace('Vraag: ', '').strip('\\n'))\n",
    "            elif line.startswith('SQL: '):\n",
    "                queries.append(line.replace('SQL: ', '').strip('\\n'))\n",
    "    return {'questions': questions, 'queries':queries}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23f4129",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = read_dataset('./text2sql/datasets/text2sql-trainset.txt')\n",
    "test = read_dataset('./text2sql/datasets/text2sql-testset.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c93455",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiments(dataset: dict, method, **kwargs) -> list:\n",
    "    results = []\n",
    "    runtime = []\n",
    "    for question, query in zip(dataset['questions'], dataset['queries']):\n",
    "        with contextlib.redirect_stdout(io.StringIO()) as s:\n",
    "            start = timeit.default_timer()\n",
    "            method(question, **kwargs)\n",
    "            end = timeit.default_timer()\n",
    "            results.append(s.getvalue().strip('\\n'))\n",
    "            runtime.append(end - start)\n",
    "    return results, np.array(runtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cea4c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rule_based(question: str, **kwargs):\n",
    "    filtered_question = cfg.vocabulary.filter_question_words(question)\n",
    "    # print(f'filtered question: {filtered_question}')\n",
    "    input = InputStream(filtered_question)\n",
    "    lexer = text2sqlLexer(input)\n",
    "    tokens = CommonTokenStream(lexer)\n",
    "    parser = text2sqlParser(tokens)\n",
    "    tree = parser.prog()\n",
    "    listener = text2sqlListener()\n",
    "    walker = ParseTreeWalker()\n",
    "    walker.walk(listener, tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca38b0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_train_rule_based, runtime_train_rule_based = run_experiments(train, rule_based)\n",
    "results_test_rule_based, runtime_test_rule_based = run_experiments(test, rule_based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b382fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_based(question: str, **kwargs):\n",
    "    client = kwargs['client']\n",
    "    print(client.generate(client.conversation+[{'role': 'user', 'content': question}]).replace('```sql\\n', '').replace('```', '').replace('\\n', ' ').strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c51bdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "client_zero_shot = AzureClient(**dict(CONFIG['AZURE'].items()))\n",
    "client_zero_shot.append_conversation(role='user', content='''\n",
    "                           Jij bent een expert in SQL en jouw taak is om vragen geschreven in natuurlijke taal te vertalen naar geldige SQL queries. \n",
    "                           De database waarmee je werkt bevat de volgende SQL tabel:\n",
    "                           ```sql\n",
    "                           CREATE TABLE IF NOT EXISTS vulnerability (\n",
    "                            cve VARCHAR(255),\n",
    "                            title TEXT,\n",
    "                            confidence INT,\n",
    "                            severity VARCHAR(50), -- een van \"informational\", \"low\", \"medium\", \"high\" or \"critical\"\n",
    "                            cvss DECIMAL(4,2), -- een decimaal getal tussen 0 en 10\n",
    "                            epss DECIMAL(4,2),\n",
    "                            cwe VARCHAR(255),\n",
    "                            age INT, -- leeftijd van kwetsbaarheid in dagen\n",
    "                            kev BOOLEAN\n",
    "                           );\n",
    "                           ```\n",
    "                           Als je een vraag krijgt moet je die naar een SQL query vertalen die met de bovenstaande tabel moet werken. Als de vraag onbestaande kolomnamen bevat of als je de vraag niet kan vertalen, geef dat gewoon aan.\n",
    "                           Maak geen nieuwe kolommen aan en veronstschuldig je niet.\n",
    "                           ''')\n",
    "\n",
    "results_train_llm_based_zero_shot, runtime_train_llm_based_zero_shot = run_experiments(train, llm_based, client=client_zero_shot)\n",
    "results_test_llm_based_zero_shot, runtime_test_llm_based_zero_shot = run_experiments(test, llm_based, client=client_zero_shot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c305a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "client_few_shot = AzureClient(**dict(CONFIG['AZURE'].items()))\n",
    "client_few_shot.append_conversation(role='user', content='''\n",
    "                           Jij bent een expert in SQL en jouw taak is om vragen geschreven in natuurlijke taal te vertalen naar geldige SQL queries. \n",
    "                           De database waarmee je werkt bevat de volgende SQL tabel:\n",
    "                           ```sql\n",
    "                           CREATE TABLE IF NOT EXISTS vulnerability (\n",
    "                            cve VARCHAR(255),\n",
    "                            title TEXT,\n",
    "                            confidence INT,\n",
    "                            severity VARCHAR(50), -- een van \"informational\", \"low\", \"medium\", \"high\" or \"critical\"\n",
    "                            cvss DECIMAL(4,2), -- een decimaal getal tussen 0 en 10\n",
    "                            epss DECIMAL(4,2),\n",
    "                            cwe VARCHAR(255),\n",
    "                            age INT, -- leeftijd van kwetsbaarheid in dagen\n",
    "                            kev BOOLEAN\n",
    "                           );\n",
    "                           ```\n",
    "                           Als je een vraag krijgt moet je die naar een SQL query vertalen die met de bovenstaande tabel moet werken. Als de vraag onbestaande kolomnamen bevat of als je de vraag niet kan vertalen, geef dat gewoon aan.\n",
    "                           Maak geen nieuwe kolommen aan en veronstschuldig je niet.\n",
    "                           Hieronder vind je een aantal voorbeelden:\n",
    "                           \n",
    "                           Voorbeeld 1:\n",
    "                           Vraag: Geef de titel en ernst weer van alle kwetsbaarheden.\n",
    "                           Query: SELECT title, severity FROM vulnerability;\n",
    "                                    \n",
    "                           Voorbeeld 2:\n",
    "                           Vraag: Geef de 3 oudste kwetsbaarheden weer.\n",
    "                           SQL: SELECT * FROM vulnerability ORDER BY age DESC LIMIT 3;\n",
    "                                    \n",
    "                           Voorbeeld 3:\n",
    "                           Vraag: Geef de CVE en titel weer van alle kwetsbaarheden waarvan de titel eindigt op 'Vulnerability'.\n",
    "                           SQL: SELECT cve, title FROM vulnerability WHERE title LIKE '%Vulnerability';\n",
    "                           ''')\n",
    "\n",
    "results_train_llm_based_few_shot, runtime_train_llm_based_few_shot = run_experiments(train, llm_based, client=client_few_shot)\n",
    "results_test_llm_based_few_shot, runtime_test_llm_based_few_shot = run_experiments(test, llm_based, client=client_few_shot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7070cecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_pickle(obj, file:str):\n",
    "    with open(file, 'wb') as f:\n",
    "        pickle.dump(obj, f)\n",
    "\n",
    "def load_pickle(file) -> list:\n",
    "    with open(file, 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17802485",
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_pickle(results_train_rule_based, 'text2sql_results/results_train_rule_based.pkl')\n",
    "dump_pickle(results_train_llm_based_zero_shot, 'text2sql_results/results_train_llm_based_zero_shot.pkl')\n",
    "dump_pickle(results_train_llm_based_few_shot, 'text2sql_results/results_train_llm_based_few_shot.pkl')\n",
    "dump_pickle(results_test_rule_based, 'text2sql_results/results_test_rule_based.pkl')\n",
    "dump_pickle(results_test_llm_based_zero_shot, 'text2sql_results/results_test_llm_based_zero_shot.pkl')\n",
    "dump_pickle(results_test_llm_based_few_shot, 'text2sql_results/results_test_llm_based_few_shot.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeab813d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_pickle(runtime_train_rule_based, 'text2sql_results/runtime_train_rule_based.pkl')\n",
    "dump_pickle(runtime_train_llm_based_zero_shot, 'text2sql_results/runtime_train_llm_based_zero_shot.pkl')\n",
    "dump_pickle(runtime_train_llm_based_few_shot, 'text2sql_results/runtime_train_llm_based_few_shot.pkl')\n",
    "dump_pickle(runtime_test_rule_based, 'text2sql_results/runtime_test_rule_based.pkl')\n",
    "dump_pickle(runtime_test_llm_based_zero_shot, 'text2sql_results/runtime_test_llm_based_zero_shot.pkl')\n",
    "dump_pickle(runtime_test_llm_based_few_shot, 'text2sql_results/runtime_test_llm_based_few_shot.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ed11b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert results_train_rule_based == load_pickle('text2sql_results/results_train_rule_based.pkl')\n",
    "assert results_train_llm_based_zero_shot == load_pickle('text2sql_results/results_train_llm_based_zero_shot.pkl')\n",
    "assert results_train_llm_based_few_shot == load_pickle('text2sql_results/results_train_llm_based_few_shot.pkl')\n",
    "assert results_test_rule_based == load_pickle('text2sql_results/results_test_rule_based.pkl')\n",
    "assert results_test_llm_based_zero_shot == load_pickle('text2sql_results/results_test_llm_based_zero_shot.pkl')\n",
    "assert results_test_llm_based_few_shot == load_pickle('text2sql_results/results_test_llm_based_few_shot.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09146713",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.array_equal(runtime_train_rule_based, load_pickle('text2sql_results/runtime_train_rule_based.pkl'))\n",
    "assert np.array_equal(runtime_train_llm_based_zero_shot, load_pickle('text2sql_results/runtime_train_llm_based_zero_shot.pkl'))\n",
    "assert np.array_equal(runtime_train_llm_based_few_shot, load_pickle('text2sql_results/runtime_train_llm_based_few_shot.pkl'))\n",
    "assert np.array_equal(runtime_test_rule_based, load_pickle('text2sql_results/runtime_test_rule_based.pkl'))\n",
    "assert np.array_equal(runtime_test_llm_based_zero_shot, load_pickle('text2sql_results/runtime_test_llm_based_zero_shot.pkl'))\n",
    "assert np.array_equal(runtime_test_llm_based_few_shot, load_pickle('text2sql_results/runtime_test_llm_based_few_shot.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba4f3c5",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa9c3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_select_columns(hypothesis: str, reference: str) -> bool:\n",
    "    matched_hypothesis = re.search(r'SELECT(?:DISTINCT)?(?P<columns>.*)(?P<rest>FROM\\s?.*)', hypothesis)\n",
    "    matched_reference = re.search(r'SELECT(?:DISTINCT)?(?P<columns>.*)(?P<rest>FROM\\s?.*)', reference)\n",
    "    if matched_hypothesis and matched_reference:\n",
    "        columns_hypothesis, rest_hypothesis = matched_hypothesis.groups()\n",
    "        columns_reference, rest_reference = matched_reference.groups()\n",
    "        return columns_hypothesis != columns_reference and rest_hypothesis == rest_reference\n",
    "    return False\n",
    "\n",
    "def validate_sql(query: str) -> None|str:\n",
    "    with mysql.connector.connect(**CONFIG['DB']) as connection:\n",
    "        with connection.cursor(dictionary=True, prepared=True) as cursor:\n",
    "            try:\n",
    "                cursor.execute(query)\n",
    "                for bla in cursor.fetchall():\n",
    "                    print(bla)\n",
    "            except mysql.connector.errors.InterfaceError as e:\n",
    "                return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8adc640",
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_sql(\"SELECT title FROM vulnerability WHERE title LIKE '[a-z]%';\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e1552d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_outputs(output: list[str], ground_truth: list[str]) -> dict:\n",
    "    result = {'correct':[], 'different_valid':[], 'syntax_error':[], 'invalid_column':[]}\n",
    "    for i, (hypothesis, reference) in enumerate(zip(output, ground_truth)):\n",
    "        if hypothesis.lower().replace(' ', '') == reference.lower().replace(' ', ''):\n",
    "            result['correct'].append((hypothesis, i))\n",
    "            continue\n",
    "        if sql_error := validate_sql(hypothesis):\n",
    "            if sql_error.msg.startswith('You have an error in your SQL syntax'):\n",
    "                result['syntax_error'].append((hypothesis, i))\n",
    "                continue\n",
    "            if sql_error.msg.startswith('Unknown column'):\n",
    "                result['invalid_column'].append((hypothesis, i))\n",
    "                continue\n",
    "        result['different_valid'].append((hypothesis, i))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab53443",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_rule_based_train = evaluate_outputs(results_train_rule_based, train['queries'])\n",
    "evaluation_rule_based_test = evaluate_outputs(results_test_rule_based, test['queries'])\n",
    "evaluation_zero_shot_train = evaluate_outputs(results_train_llm_based_zero_shot, train['queries'])\n",
    "evaluation_zero_shot_test = evaluate_outputs(results_test_llm_based_zero_shot, test['queries'])\n",
    "evaluation_few_shot_train = evaluate_outputs(results_train_llm_based_few_shot, train['queries'])\n",
    "evaluation_few_shot_test = evaluate_outputs(results_test_llm_based_few_shot, test['queries'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bbed3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_statistics(evaluation_dict, title):\n",
    "    print(f'Statistics for {title}:')\n",
    "    print(f'Correct: {len(evaluation_dict['correct'])}')\n",
    "    print(f'Different but valid: {len(evaluation_dict['different_valid'])}')\n",
    "    print(f'Syntax error: {len(evaluation_dict['syntax_error'])}')\n",
    "    print('*'*35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e391c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_statistics(evaluation_rule_based_train, 'Rule-based train')\n",
    "print_statistics(evaluation_rule_based_test, 'Rule-based test')\n",
    "print_statistics(evaluation_zero_shot_train, 'LLM-based zero-shot train')\n",
    "print_statistics(evaluation_zero_shot_test, 'LLM-based zero-shot test')\n",
    "print_statistics(evaluation_few_shot_train, 'LLM-based few-shot train')\n",
    "print_statistics(evaluation_few_shot_test, 'LLM-based few-shot test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4754b0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for produced, ground_truth_index in evaluation_zero_shot_train['different_valid']:\n",
    "    print(f'Ground truth: {train['queries'][ground_truth_index]}')\n",
    "    print(f'Produced: {produced}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8926ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_runtime(runtime: np.ndarray, title):\n",
    "    fig, ax = plt.subplots(figsize=(12,9))\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel('Runtime (seconds)')\n",
    "    ax.set_ylabel('Number of queries')\n",
    "    ax.hist(runtime)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335fb008",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_runtime(runtime_train_rule_based, 'Runtime of the 50 training questions on the rule-based system')\n",
    "plot_runtime(runtime_test_rule_based, 'Runtime of the 50 test questions on the rule-based system')\n",
    "plot_runtime(runtime_train_llm_based_zero_shot, 'Runtime of the 50 train questions on the zero-shot LLM-based system')\n",
    "plot_runtime(runtime_test_llm_based_zero_shot, 'Runtime of the 50 test questions on the zero-shot LLM-based system')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3b67d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter_plot_runtime(runtime: np.ndarray, title=None, yticks=None):\n",
    "    fig, ax = plt.subplots(figsize=(12,9))\n",
    "    ax.plot(np.arange(1,51), runtime, linestyle='--', marker='o')\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel('Sample number', fontsize=16)\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), fontsize=16)\n",
    "    ax.set_ylabel('Runtime (seconds)', fontsize=16)\n",
    "    if yticks is not None:\n",
    "        ax.set_yticks(yticks)\n",
    "    ax.set_yticklabels(ax.get_yticklabels(), fontsize=16)\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb1706e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_plot_runtime(runtime_train_rule_based)\n",
    "scatter_plot_runtime(runtime_train_llm_based_zero_shot, yticks=np.arange(0,50,5))\n",
    "scatter_plot_runtime(runtime_train_llm_based_few_shot)\n",
    "scatter_plot_runtime(runtime_test_rule_based)\n",
    "scatter_plot_runtime(runtime_test_llm_based_zero_shot, yticks=np.arange(0,50,5))\n",
    "scatter_plot_runtime(runtime_test_llm_based_few_shot)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "talking-with-vulns-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
